{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Classification\n",
    "\n",
    "There are two most common tasks in **supervised machine learning**: **regression** (predicting values) and **classification** (predicting classes). In this chapter, we focuse on building classification systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We will use the MNIST dataset of handwritten images as an example.\n",
    "\n",
    "- Load MNIST dataset using sklearn.datasets.fetch_mldata() or from http://yann.lecun.com/exdb/mnist/ with python-mnist package.\n",
    "- Construct training set and test set. We will use training set to build the classifier, and use test set to evaluate its performance.\n",
    "- Explore the dataset (find size of dataset, show a random image, show multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([0, 0, 0, ..., 9, 9, 9], dtype=int8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n",
    "    sort_by_target(mnist) # fetch_openml() returns an unsorted dataset\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist['data']\n",
    "labels = mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  37., 255., 135.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  49., 253., 193.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 157., 253.,\n",
       "       175.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  40., 222., 244.,  58.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  59., 253.,\n",
       "       119.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   6., 180.,  84.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 149., 136.,\n",
       "       120.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  47., 254., 253.,  96.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 179., 254.,\n",
       "       243.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  53., 242., 254., 114.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 110., 254.,\n",
       "       249.,  52.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 179., 253., 161.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14., 234.,\n",
       "       253.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 121., 253., 230.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  21., 226.,\n",
       "       253., 104.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  21., 191., 253., 222.,   8.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  73., 253.,\n",
       "       180.,  97.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 177., 253.,  36.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  27., 219.,\n",
       "       253.,  36.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  61., 253., 213.,  19.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = images[12345]\n",
    "some_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26081445400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADdlJREFUeJzt3X+o1fUdx/HXu+b+sK0ovDpp6W3DRhHkxkEGlbeIfo3ABhlJDBdrCk2YMXBhiIINJPbDghHdzdsUtnKgLgNZSqzuBjG8Ra7WdVPipk7RK62WEkn23h/367jTez7ndL6/zvX9fIDcc77v872ftwdffs85n+/5fszdBSCeC+puAEA9CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaA+V+Vg06ZN897e3iqHBEIZGRnR8ePHrZ3H5gq/md0h6QlJF0r6tbuvSz2+t7dXQ0NDeYYEkNBoNNp+bMcv+83sQkm/lHSnpGskLTKzazr9fQCqlec9/zxJ+939HXc/Jek5SQuKaQtA2fKE/3JJB8fdP5Rt+z9mtsTMhsxsaHR0NMdwAIqUJ/wTfahwzveD3b3f3Rvu3ujp6ckxHIAi5Qn/IUlXjLv/ZUmH87UDoCp5wr9b0hwzu9LMPi/pPknbi2kLQNk6nupz90/MbJmkFzU21Tfg7n8vrDMApco1z+/uOyTtKKgXABXi9F4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqp0iW5gvE2bNiXrH3zwQbK+devWZP3ll19uWmu1VPyOHemLUl999dXJ+mTAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgso1z29mI5I+lHRa0ifu3iiiKZw/rrrqqqa1gwcPJvc9depUrrHNrGltxowZyX2nTZuWa+zJoIiTfG529+MF/B4AFeJlPxBU3vC7pJ1m9pqZLSmiIQDVyPuy/3p3P2xm0yXtMrO97j44/gHZfwpLJGnWrFk5hwNQlFxHfnc/nP08JmmbpHkTPKbf3Rvu3ujp6ckzHIACdRx+M7vIzL545rak2yS9VVRjAMqV52X/DEnbsumUz0n6nbv/sZCuAJSu4/C7+zuSriuwF9Tg5MmTyfqePXuS9cceeyxZ379/f9Naah6+bMPDw8n63r17k/Xz4S0sU31AUIQfCIrwA0ERfiAowg8ERfiBoLh0d3DLly9P1gcGBirqpFrz589P1m+44YaKOqkPR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIp5/vPck08+may/8MILFXXSXVotwb1z585k/fbbby+ynVpw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoJjnnwRaXV479Z38DRs2JPet8/LZderr60vWb7zxxoo6qQ9HfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquU8v5kNSLpL0jF3vzbbdpmkzZJ6JY1Iutfd/11em7G1Wia7m6+tP2fOnKa1Cy5IH3s+/vjjZP3dd9/tqCep9RLdb7/9drLeaDQ6HrtbtHPk/42kO87a9oikl9x9jqSXsvsAJpGW4Xf3QUnvnbV5gaSN2e2Nku4uuC8AJev0Pf8Mdz8iSdnP6cW1BKAKpX/gZ2ZLzGzIzIZGR0fLHg5AmzoN/1EzmylJ2c9jzR7o7v3u3nD3Rk9PT4fDAShap+HfLmlxdnuxpOeLaQdAVVqG38yelfSqpK+Z2SEz+56kdZJuNbN9km7N7gOYRFrO87v7oialWwruJay1a9cm688880xFnZxr+vT0Z7mPPvposr5s2bKOx163Ln1MaTV2ytKlS5P1CG9ROcMPCIrwA0ERfiAowg8ERfiBoAg/EBSX7q5Aq2WyV69eXdrY7p5r/4svvjhZzzOVl1erv1uqPmvWrOS+s2fP7qinyYQjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTx/AVpd5nnv3r3Jep3LZD/00EPJ+ooVK0obu9Vl3QYHB5P1Vs9baq7+wIEDyX0j4MgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exz1+A/v7+ZP3pp5+uqJNzPfjgg8n6448/nqxPnTo11/ivvPJK01qrS2+/+uqrucZesGBB09qaNWty/e7zAUd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq5Ty/mQ1IukvSMXe/Ntu2RtL3JZ35QvZKd99RVpPdIPXd89Rcdt1anYNQtr6+vqa1Vt/nR7naOfL/RtIdE2z/hbvPzf6c18EHzkctw+/ug5Leq6AXABXK855/mZn9zcwGzOzSwjoCUIlOw/+UpK9KmivpiKSfNXugmS0xsyEzG+I9HtA9Ogq/ux9199Pu/qmkX0mal3hsv7s33L3R09PTaZ8ACtZR+M1s5ri735b0VjHtAKhKO1N9z0q6SdI0MzskabWkm8xsriSXNCJpaYk9AihBy/C7+6IJNm8ooZeutnjx4qa1PXv2lDp26nvpkvTwww+XOn4eCxcubFrbt29fqWOvX7++1N8/2XGGHxAU4QeCIvxAUIQfCIrwA0ERfiAoLt3dpnvuuadp7cUXXyx17Pnz5+eq53Hy5Mlkffny5cn6li1bmtbyLk2+atWqXPtHx5EfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Jinj+ze/fuZH3lypUVdXKuVstJ79q1q7SxP/roo2R9cHCwtLHXrl2brN9///2ljR0BR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIp5/sz06dOT9dRqQ2UvQ3bixIlkPXU9AXdP7pv3O/VlGhkZSdZnz55dTSPnKY78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUy3l+M7tC0iZJX5L0qaR+d3/CzC6TtFlSr6QRSfe6+7/La7VcrebDU/VW+9ap7t5S46eWPZe6e+nx80E7R/5PJP3I3a+W9E1JPzCzayQ9Iukld58j6aXsPoBJomX43f2Iu7+e3f5Q0rCkyyUtkLQxe9hGSXeX1SSA4n2m9/xm1ivp65L+KmmGux+Rxv6DkJQ+PxZAV2k7/Gb2BUlbJC139/98hv2WmNmQmQ2VfQ48gPa1FX4zm6Kx4P/W3bdmm4+a2cysPlPSsYn2dfd+d2+4eyP15RgA1WoZfhv72tcGScPu/vNxpe2Sznxcu1jS88W3B6As7Xyl93pJ35H0ppm9kW1bKWmdpN+b2fckHZC0sJwWq9HqK72pZbCHh4eLbqcyZX+lt6+vr2lt/fr1yX0vueSSotvBOC3D7+5/kdTsX8gtxbYDoCqc4QcERfiBoAg/EBThB4Ii/EBQhB8Iikt3Z6ZOnZqsr1ixomlt8+bNyX3ff//9jnrqBtddd12y3mg0Ov7dU6ZM6Xhf5MeRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYp6/Tb29vU1r27ZtS+578803F9xNcVatWpWsP/DAA8k6y2RPXhz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo5vkLkLqmvySdPn26ok6A9nHkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgWobfzK4wsz+Z2bCZ/d3MfphtX2Nm/zKzN7I/3yq/XQBFaeckn08k/cjdXzezL0p6zcx2ZbVfuPtPy2sPQFlaht/dj0g6kt3+0MyGJV1edmMAyvWZ3vObWa+kr0v6a7ZpmZn9zcwGzOzSJvssMbMhMxsaHR3N1SyA4rQdfjP7gqQtkpa7+38kPSXpq5LmauyVwc8m2s/d+9294e6Nnp6eAloGUIS2wm9mUzQW/N+6+1ZJcvej7n7a3T+V9CtJ88prE0DR2vm03yRtkDTs7j8ft33muId9W9JbxbcHoCztfNp/vaTvSHrTzN7Itq2UtMjM5kpySSOSlpbSIYBStPNp/18k2QSlHcW3A6AqnOEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iyty9usHMRiW9O27TNEnHK2vgs+nW3rq1L4neOlVkb7Pdva3r5VUa/nMGNxty90ZtDSR0a2/d2pdEb52qqzde9gNBEX4gqLrD31/z+Cnd2lu39iXRW6dq6a3W9/wA6lP3kR9ATWoJv5ndYWb/MLP9ZvZIHT00Y2YjZvZmtvLwUM29DJjZMTN7a9y2y8xsl5nty35OuExaTb11xcrNiZWla33uum3F68pf9pvZhZL+KelWSYck7Za0yN3frrSRJsxsRFLD3WufEzaz+ZJOSNrk7tdm2x6X9J67r8v+47zU3X/cJb2tkXSi7pWbswVlZo5fWVrS3ZK+qxqfu0Rf96qG562OI/88Sfvd/R13PyXpOUkLauij67n7oKT3ztq8QNLG7PZGjf3jqVyT3rqCux9x99ez2x9KOrOydK3PXaKvWtQR/sslHRx3/5C6a8lvl7TTzF4zsyV1NzOBGdmy6WeWT59ecz9na7lyc5XOWlm6a567Tla8Llod4Z9o9Z9umnK43t2/IelOST/IXt6iPW2t3FyVCVaW7gqdrnhdtDrCf0jSFePuf1nS4Rr6mJC7H85+HpO0Td23+vDRM4ukZj+P1dzP/3TTys0TrSytLnjuumnF6zrCv1vSHDO70sw+L+k+Sdtr6OMcZnZR9kGMzOwiSbep+1Yf3i5pcXZ7saTna+zl/3TLys3NVpZWzc9dt614XctJPtlUxnpJF0oacPefVN7EBMzsKxo72ktji5j+rs7ezOxZSTdp7FtfRyWtlvQHSb+XNEvSAUkL3b3yD96a9HaTxl66/m/l5jPvsSvu7QZJf5b0pqRPs80rNfb+urbnLtHXItXwvHGGHxAUZ/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwjqv55Q+e4oPRi6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use imshow() from matplotlib to show the image\n",
    "some_digit = images[123]\n",
    "some_digit = some_digit.reshape([28, 28])\n",
    "plt.imshow(some_digit,\n",
    "           cmap=mpl.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Binary Clasifier\n",
    "\n",
    "To start, we aim at building a binary classifier to identify if an handwritten digit is five.\n",
    "\n",
    "- Create the labels for binary classification (1 for five, and 0 for all other digits)\n",
    "- Apply the **k-nearest-neighbor algorithm** using sklearn.neighbors.KNeighborsClassifier.\n",
    "- Use its fit() method to train the model, use predict method to make predictions on given images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7877\n",
       "7    7293\n",
       "3    7141\n",
       "2    6990\n",
       "9    6958\n",
       "0    6903\n",
       "6    6876\n",
       "8    6825\n",
       "4    6824\n",
       "5    6313\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array labels_5 to store the truth value of the label being 5 \n",
    "labels_5 = (labels == 5)\n",
    "df_labels = pd.DataFrame(labels, columns = ['Label'])\n",
    "df_labels['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    63687\n",
       "True      6313\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_5 = pd.DataFrame(labels_5, columns = ['Label'])\n",
    "df_labels_5['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the orginal labels are sorted\n",
    "labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training set and test set\n",
    "\n",
    "We must reserve a portion of the data to test the model. The training set is used to train the model, and usually cannot be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set, usually we take about 15% as test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images, test_images, train_labels_5, test_labels_5 = train_test_split(images, labels_5, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59500, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "        True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_5[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply KNeighborsClassifier to build a binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY SLOW, apply KNN model to build the binary classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_jobs = 1)\n",
    "knn.fit(train_images, train_labels_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY SLOW, use the model to make predictions on the test set\n",
    "predictions_knn = knn.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGDClassifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train_images, train_labels_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sgd.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance of a Classifier\n",
    "\n",
    "- Use sklearn.metrics.accuracy_score to calculate classification accuracy on the training set and on the test set.\n",
    "- Display the images where the model predicts wrong.\n",
    "- Use cross-validation to evaluate the performance of the model on various training and test sets.\n",
    "- Use confusion matrix to show the percentage of **false positives** and **true negatives**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy = accuracy_score(test_labels_5, predictions)\n",
    "train_predictions = sgd.predict(train_images)\n",
    "train_accuracy = accuracy_score(train_labels_5, train_predictions)\n",
    "print(test_accuracy, train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation\n",
    "- partition the dataset into k mutully-exclusive subsets\n",
    "- perform training on all but the 1st set, test the performance on the 1st set.\n",
    "- perform training on all but the 2nd set, test the performance on the 2nd set.\n",
    "- perform training on all but the 3rd set, test the performance on the 3rd set.\n",
    "- ....\n",
    "- perform training on all but the last set, test the performance on the last set.\n",
    "\n",
    "In this way, the model is tested on k different training sets. If all performances are acceptable, we should have high confidence on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy_scores = cross_val_score(sgd, train_images, train_labels_5, cv=5,\n",
    "                                 scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "For each pair of class A and B:\n",
    "- count the number of instances of class A being classified as B\n",
    "- count the number of instances of class B being classified as A\n",
    "\n",
    "The numbers will form an $n\\times n$ matrix, where $n$ is the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(test_labels_5, predictions)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For binary classifiers**:\n",
    "confusion matrx = [[TN, FP], [FN, TP]]\n",
    "\n",
    "- TN: true negative\n",
    "- FP: false positive\n",
    "- FN: false negative\n",
    "- TP: true positive\n",
    "\n",
    "**Precision** = TP / (TP + FP)\n",
    "\n",
    "- What does precision represent?\n",
    "- Can a bad model have high precision?\n",
    "\n",
    "\n",
    "**Recall** = TP / (TP + FN)\n",
    "- What does recall represent?\n",
    "- Can a bad model have high recall?\n",
    "\n",
    "$F_1$ **score**\n",
    "\n",
    "$F_1 = \\frac{1}{\\frac{1}{precision} + \\frac{1}{recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Performance Measures\n",
    "\n",
    "- Precision-Recall tradeoff\n",
    "- Distribution of scores\n",
    "- ROC curve: False positive vs. True Positive\n",
    "- AUC (Area under curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "- Some models can directly handle multiple classes (Random forest, naive Bayes, neural networks)\n",
    "- One vs. All: build a binary classifier for each class, compare their prediction scores\n",
    "- One vs. One: build a binary classifier for each pair of classes, and see which class wins most duels\n",
    "\n",
    "**Q: How to evaluate a multiclass classifier?**\n",
    "\n",
    "Further topics:\n",
    "\n",
    "- multilabel classification\n",
    "- multioutput classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. Training machine learning models on MNIST data with augmentation:\n",
    "    - Use scipy.ndimage.interpolation.shift() function to shift each image in the MNIST training dataset in the following ways: 1) 1 pixel up; 2) 1 pixel down; 3) 1 pixel to the left; 4) 1 pixel to the right.\n",
    "    - Use SGDClassifier to build a binary classifier on the augmented dataset that identifies if the image is **9**.\n",
    "    - Evaluate the performance of the classifier by showing: 1) test accuracy; 2) confusion matrix; \n",
    "\n",
    "2. (extra credits) Chapter 3 Exercise 4: Build a spam classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval = 0, mode = \"constant\")\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_images[1000]\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "shifted_image_up = shift_image(image, 0, -1)\n",
    "shifted_image_down = shift_image(image, 0, 1)\n",
    "shifted_image_left = shift_image(image, -1, 0)\n",
    "shifted_image_right = shift_image(image, 1, 0)\n",
    "\n",
    "print(\"label: \", train_labels[1000])\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.subplot(231)\n",
    "plt.title(\"Original\", fontsize = 14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation = \"nearest\", cmap = \"Greys\")\n",
    "plt.subplot(232)\n",
    "plt.title(\"Shifted up\", fontsize = 14)\n",
    "plt.imshow(shifted_image_up.reshape(28, 28), interpolation = \"nearest\", cmap = \"Greys\")\n",
    "plt.subplot(233)\n",
    "plt.title(\"Shifted down\", fontsize = 14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation = \"nearest\", cmap = \"Greys\")\n",
    "plt.subplot(234)\n",
    "plt.title(\"Shifted left\", fontsize = 14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation = \"nearest\", cmap = \"Greys\")\n",
    "plt.subplot(235)\n",
    "plt.title(\"Shifted right\", fontsize = 14)\n",
    "plt.imshow(shifted_image_right.reshape(28, 28), interpolation = \"nearest\", cmap = \"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classifier for the number 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_9 = (labels == 9)\n",
    "df_labels = pd.DataFrame(labels, columns = ['Label']) # comment out, may not be necessary if already ran earlier\n",
    "df_labels['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_9 = pd.DataFrame(labels_9, columns = ['Label'])\n",
    "df_labels_9['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the orginial labels are sorted\n",
    "labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images, test_images, train_labels_9, test_labels_9 = train_test_split(images, labels+9, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_9[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN being used for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_jobs = 1)\n",
    "knn.fit(train_images, train_labels_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = knn.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train_images, train_labels_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sgd.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance of the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy = accuracy_score(test_labels_9, predictions)\n",
    "train_predictions = sgd.predict(train_images)\n",
    "train_accuracy = accuracy_score(train_labels_9, train_predictions)\n",
    "print(test_accuracy, train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy_scores = cross_val_score(sgd, train_images, train_labels_9, cv = 9, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(test_labels_9, predictions)\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
