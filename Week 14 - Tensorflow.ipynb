{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "\n",
    "The second quiz will take place this Wednesday:\n",
    "- 45 minutes\n",
    "- SVM, decision tree, neural network\n",
    "\n",
    "\n",
    "# Final Project Schedule\n",
    "**Proposal **\n",
    "\n",
    "- Form a team of 1-3 students (3-student team is only allowed if the project is significantly more complex than the mid-term project)\n",
    "- Describe the background of the problem,\n",
    "- Describe where to get the data,\n",
    "- Frame the Machine Learning problem: What are input features? What are the model expected to learn? Is it supervised learning / unsupervised learning? Is it a classification / regression problem?\n",
    "- Describe briefly the research plan: what models to use? How to measure the performance?\n",
    "\n",
    "**Each team should submit a project proposal at the beginning of the class on Monday, May 6th.**\n",
    "\n",
    "**Project Submission**\n",
    "Each team is expected provide a Jupyter notebook containing:\n",
    "- Written description on every step and their results. For example, if you decide to build a decision tree model, you should describe how the set up the model (value of maximum depth, maximum number of leaves, etc), and explain how well the model works for the problem.\n",
    "- Executable code that performs the essential steps of the project, including: data cleaning, data visualization/summarization, model training/fine-tuning/evaluation.\n",
    "- A conclusion session that summarizes the project, with explicit statements on the outcome of the project.\n",
    "\n",
    "**Submission Deadline: Wednesday, May 22nd (last day of the exam week)**\n",
    "\n",
    "** Online data sets**\n",
    "- [Kaggle.com](kaggle.com): Gain access to their data set by entering a competition\n",
    "- [UCI machine learning repository](http://mlr.cs.umass.edu/ml/) is one of the oldest sources of data sets on the web. These data sets tend to be fairly small, but are usually clean and ready for machine learning to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "\n",
    "TensorFlow is an open source software library for high performance numerical computation.\n",
    "- Originally it was developed by Google Brain team, and now it is one of the most popular open source projects on GitHub (check out https://github.com/jtoy/awesome-tensorflow)\n",
    "- Its basic principle is simple: first define in Python a graph of computations to perform, and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.\n",
    "![](Data/tf_1.png)\n",
    "- TensorFlow can break up the graph into several chuncks and run them in parallel across multiple CPUs , GPUs, Tensor Processing Units (TPUs), and from desktops to clusters of servers to mobile and edge devices.\n",
    "- It comes with a great visualization tool called TensorBoard that allows you to browse through the computation graph, view learning curves, and more.\n",
    "- Google also launched a cloud service to run TensorFlow computational graphs (cloud.google.com/ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello'\n"
     ]
    }
   ],
   "source": [
    "# Create a constant string\n",
    "hello = tf.constant('hello')  \n",
    "# Create a TensorFlow session\n",
    "sess = tf.Session()\n",
    "# Print the string during a session run\n",
    "print(sess.run(hello))\n",
    "# print(hello) # this will not work; must execute in a session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow Graph\n",
    "TensorFlow uses a **dataflow graph** to represent your computation in terms of the dependencies between individual operations. This leads to a three-step programming procedure:\n",
    "1. Define the dataflow graph\n",
    "2. Create a TensorFlow **session**\n",
    "3. Run the graph\n",
    "\n",
    "A TensorFlow session will take care of placing the operation onto devices such as CPUs and GPUs and running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reset a dataflow graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define two variables x, y\n",
    "x = tf.Variable(3, name='x') # equivalent way in tf for x=3\n",
    "y = tf.Variable(4, name='y') # y=4\n",
    "\n",
    "# Define f based on x and y\n",
    "f = x*x*y + y + 2 \n",
    "\n",
    "# The following print statement only gives the \n",
    "# description of variable f, not its value (since\n",
    "# the value hasn't been computed yet)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow session and evaluates f\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize x and y\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "\n",
    "# Evaluate f\n",
    "result = sess.run(f)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# use with statement to set sess as default session\n",
    "with tf.Session() as sess:\n",
    "    # equivalent to sess.run(x.initializer):\n",
    "    x.initializer.run() \n",
    "    # equivalent to sess.run(y.initializer):\n",
    "    y.initializer.run()\n",
    "    # equivalent to sess.run(f)\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Use tf.global_variables_initializer() to \n",
    "# initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: \n",
    "# Create a TensorFlow graph to compute\n",
    "# S = pi * r ** 2\n",
    "# where pi=3.14, r=1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data to the graph\n",
    "We can use tf.placeholder() to delay initialization. This is particularly useful when we want to feed data to the graph during execution. The following code creates a placeholder node A, and B = A + 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "# None as a dimension means any size.\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Gradient Descent using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing data\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Gradient:**\n",
    "- Cost generated from each instance $(\\textbf{x}^{(i)}, y^{(i)})$ is: \n",
    "\n",
    "$(\\theta\\cdot\\textbf{x}^{(i)} - y^{(i)})^2 = (\\theta_0\\cdot 1 + \\theta_1x^{(i)}_1 + \\theta_2x^{(i)}_2 + \\cdots + \\theta_nx^{(i)}_n - y^{(i)})^2$.\n",
    "- Its partial derivative with respect to $\\theta_j$ is:\n",
    "\n",
    "$2x^{(i)}_j(\\theta_0\\cdot 1 + \\theta_1x^{(i)}_1 + \\theta_2x^{(i)}_2 + \\cdots + \\theta_nx^{(i)}_n - y^{(i)})$.\n",
    "- Average cost is: $\\frac{1}{m}\\sum_{i=1}^m(y^{(i)} - \\theta\\cdot\\textbf{x}^{(i)})^2$.\n",
    "- The partial derivative of the average cost with respect to $w_i$ is:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^m2x^{(i)}_j(\\theta_0\\cdot 1 + \\theta_1x^{(i)}_1 + \\theta_2x^{(i)}_2 + \\cdots + \\theta_nx^{(i)}_n - y^{(i)})$.\n",
    "\n",
    "**Use tf.gradients(ys, xs) to ask TensorFlow automatically compute the derivatives of sum of ys with respect to xs. **\n",
    "\n",
    "**The update rule of gradient descent:**\n",
    "\n",
    "$\\theta_j = \\theta_j - \\textit{(learning_rate)}\\cdot\\textit{partial derivative}$.\n",
    "\n",
    "The formula is\n",
    "\n",
    "$\\theta_j = \\theta_j - \\textit{learning_rate}\\cdot\\frac{1}{m}\\sum_{i=1}^m2x^{(i)}_j(\\theta_0\\cdot 1 + \\theta_1x^{(i)}_1 + \\theta_2x^{(i)}_2 + \\cdots + \\theta_nx^{(i)}_n - y^{(i)})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544265\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727804\n",
      "Epoch 300 MSE = 0.5585008\n",
      "Epoch 400 MSE = 0.54907006\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.5373791\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.53124255\n",
      "Epoch 900 MSE = 0.5293705\n",
      "Best theta:\n",
      "[[ 2.06855249e+00]\n",
      " [ 7.74078071e-01]\n",
      " [ 1.31192386e-01]\n",
      " [-1.17845066e-01]\n",
      " [ 1.64778143e-01]\n",
      " [ 7.44078017e-04]\n",
      " [-3.91945094e-02]\n",
      " [-8.61356676e-01]\n",
      " [-8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Neural Network using plain TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-7a719a86c2f3>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ch002\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ch002\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\ch002\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\ch002\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ch002\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('tmp/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype('int')\n",
    "y_test = mnist.test.labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32,\n",
    "                   shape=(None, n_inputs),\n",
    "                   name='x')\n",
    "y = tf.placeholder(tf.int64,\n",
    "                   shape=(None),\n",
    "                   name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal(\n",
    "            (n_inputs, n_neurons),\n",
    "            stddev=stddev\n",
    "        )\n",
    "        W = tf.Variable(init, name='weights')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]),\n",
    "                        name='bias')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        return activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(\n",
    "        X,\n",
    "        n_hidden1,\n",
    "        name='hidden1',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    hidden2 = neuron_layer(\n",
    "        hidden1,\n",
    "        n_hidden2,\n",
    "        name='hidden2',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    logits = neuron_layer(\n",
    "        hidden2,\n",
    "        n_outputs,\n",
    "        name='outputs',\n",
    "        activation=tf.identity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=logits\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy,\n",
    "                          name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate\n",
    "    )\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(correct, tf.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9109\n",
      "1 Accuracy: 0.9309\n",
      "2 Accuracy: 0.9394\n",
      "3 Accuracy: 0.9476\n",
      "4 Accuracy: 0.951\n",
      "5 Accuracy: 0.9544\n",
      "6 Accuracy: 0.958\n",
      "7 Accuracy: 0.9602\n",
      "8 Accuracy: 0.9615\n",
      "9 Accuracy: 0.9638\n",
      "10 Accuracy: 0.9649\n",
      "11 Accuracy: 0.9665\n",
      "12 Accuracy: 0.9685\n",
      "13 Accuracy: 0.9685\n",
      "14 Accuracy: 0.97\n",
      "15 Accuracy: 0.9698\n",
      "16 Accuracy: 0.9706\n",
      "17 Accuracy: 0.9719\n",
      "18 Accuracy: 0.9719\n",
      "19 Accuracy: 0.9714\n",
      "20 Accuracy: 0.9729\n",
      "21 Accuracy: 0.9731\n",
      "22 Accuracy: 0.9743\n",
      "23 Accuracy: 0.9729\n",
      "24 Accuracy: 0.9747\n",
      "25 Accuracy: 0.9742\n",
      "26 Accuracy: 0.9757\n",
      "27 Accuracy: 0.9751\n",
      "28 Accuracy: 0.9746\n",
      "29 Accuracy: 0.975\n",
      "30 Accuracy: 0.9759\n",
      "31 Accuracy: 0.9754\n",
      "32 Accuracy: 0.9769\n",
      "33 Accuracy: 0.9767\n",
      "34 Accuracy: 0.976\n",
      "35 Accuracy: 0.9767\n",
      "36 Accuracy: 0.9764\n",
      "37 Accuracy: 0.9769\n",
      "38 Accuracy: 0.9771\n",
      "39 Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op,\n",
    "                     feed_dict={X: X_batch,\n",
    "                                y: y_batch})\n",
    "        acc = accuracy.eval(\n",
    "            feed_dict={X: X_test,\n",
    "                       y: y_test}\n",
    "        )\n",
    "        print(epoch, 'Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
