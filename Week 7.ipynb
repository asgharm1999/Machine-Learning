{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We have studied how to use linear regression and polynomial regression to *predict a target numeric value*. There is another learning task, **classification**, aiming at predicting group membership rather than numeric values. Email spam filter is a good example: it is trained with many example emails with their class (spam or non-spam), and it must learn how to classify new emails.\n",
    "\n",
    "Linear regression is **not** a good choice for classification tasks. We will introduce the **logistic regression** model and use the iris dataset to illustrate how the model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "**Single-class model**: fit the probability of data belonging to the class\n",
    "\n",
    "$\\log\\frac{\\hat{p}}{1 - \\hat{p}} = h(x_1, ..., x_n),$\n",
    "\n",
    "$h(x_1, ..., x_n) = \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n.$\n",
    "- n: number of input features.\n",
    "- x_1, ..., x_n: input features\n",
    "- $\\hat{p}$: the estimated probability of data belonging to the class\n",
    "- $\\theta_1,...,\\theta_n$: parameters of the model\n",
    "\n",
    "**Alternative format**:\n",
    "\n",
    "$\\hat{p} = \\sigma(\\textbf{x}\\cdot\\theta^T).$\n",
    "\n",
    "- $\\textbf{x} = (x_1, ..., x_n)$.\n",
    "- $\\theta = (\\theta_1, ..., \\theta_n)$.\n",
    "- $\\sigma(t) = \\frac{1}{1+e^{-t}}$: logistic function\n",
    "\n",
    "**Decision rule** (adjustible):\n",
    "\n",
    "- prediction = 1 if $\\hat{p}$ $\\ge$ 0.5\n",
    "- prediction = 0 if $\\hat{p}$ < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Example: The Iris Dataset\n",
    "\n",
    "**Iris dataset** is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica. [wiki page](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "- Import dataset using <code>sklearn.dataset.load_iris()</code>\n",
    "- Explore the dataset: data description, feature names, data types, data histograms, scatter plots.\n",
    "- Split the dataset into train_set and test_set\n",
    "- Apply <code>sklearn.linear_model.LogisticRegression</code> to build a binary classifier on **Iris-Virginica**.\n",
    "- Evaluate the performance of the model: Accuracy, cross-validation, precision vs. recall, confusion matrix...\n",
    "- Visualize the model (show decision boundary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Function $\\sigma(t) = \\frac{1}{1+e^{-t}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the range of the logistic function?\n",
    "\n",
    "2. What can we say about the value of $h(x_1, ..., x_n) (=\\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n)$ if $\\hat{p}\\ge 0.5$?\n",
    "\n",
    "3. What can we say about the value of $h(x_1, ..., x_n) (=\\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n)$ if $\\hat{p}< 0.5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph of logistic function over interval [-10, 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "**Cost (loss) function** for logistic regression:\n",
    "\n",
    "\\begin{equation}\n",
    "c(\\theta) = \\left\\{\n",
    "\\begin{array}{cc}\n",
    "-\\log(\\hat{p}) & \\textit{if }y=1,\\\\\n",
    "-\\log(1-\\hat{p}) & \\textit{if }y=0.\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "The cost function $c(\\theta)$:\n",
    "\n",
    "- small if $y=1$ (data example belongs to the class) and $\\hat{p}$ is close to 1.\n",
    "- small if $y=0$ (data example does not belong to the class) and $\\hat{p}$ is close to 0.\n",
    "- is a convex function no matter what $y$ is.\n",
    "\n",
    "**Uniformed expression for the cost function**:\n",
    "\n",
    "$J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}\\big[y^{(i)}\\log(\\hat{p}^{(i)}) + (1-y^{(i)})\\log(1-\\hat{p}^{(i)})\\big]$\n",
    "\n",
    "- $c(\\theta) = J(\\theta)$ for $y=0$ and $y=1$.\n",
    "- There is no equivalent of the Normal Equation.\n",
    "- $J(\\theta)$ is a convex function.\n",
    "- $\\frac{\\partial J}{\\partial \\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\big(\\sigma(\\textbf{x}^{(i)}\\cdot\\theta^T) - y^{(i)}\\big)x_j^{(i)}$.\n",
    "\n",
    "**Question**: Why not use the mean-square-error (SME) cost function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression for Multiple Classes (Softmax regression)\n",
    "**model**:\n",
    "\n",
    "$\\hat{p}_k = \\frac{\\exp(s_k(\\textbf{x}))}{\\sum_{i=1}^K\\exp(s_i(\\textbf{x}))}$.\n",
    "\n",
    "$s_k(\\textbf{x}) = \\textbf{x}\\cdot\\theta_k^T$\n",
    "\n",
    "- $\\hat{p}_k$ is the probability that the instance belongs to class $k$.\n",
    "- K is the number of classes.\n",
    "- $\\theta_k$ is the coefficient vector associated with class $k$. All these vectors are stored as rows in a parameter matrix $\\Theta$.\n",
    "- The softmax classifier predicts the class with the highest estimated probability (which is simply the class with the highest score).\n",
    "\n",
    "**Cross entropy cost function**\n",
    "\n",
    "$J(\\Theta) = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^K\n",
    "y_k^{(i)}\\log(\\hat{p}_k^{(i)})$\n",
    "\n",
    "- $y_k^{(i)}$ is equal to 1 if the target for the i-th instance is $k$; otherwise, it is equal to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework:\n",
    "\n",
    "1. Build a logistic classifier to identify Iris-Setosa based only on its petal width. Divide the dataset randomly into 80% training set and 20% test set, show accuracy on test set.\n",
    "2. Visualize the model by showing the probability curve and decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
